{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jHOC2HC0sCNE"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUmK767kWQlq",
        "outputId": "54e17ae5-f22f-4008-a6d8-2de8d9eb718e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mask2Former' already exists and is not an empty directory.\n",
            "/content/Mask2Former\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Collecting git+https://github.com/cocodataset/panopticapi.git\n",
            "  Cloning https://github.com/cocodataset/panopticapi.git to /tmp/pip-req-build-viu9kht6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/panopticapi.git /tmp/pip-req-build-viu9kht6\n",
            "  Resolved https://github.com/cocodataset/panopticapi.git to commit 7bb4655548f98f3fedc07bf37e9040a992b054b0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from panopticapi==0.1) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from panopticapi==0.1) (9.4.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.0.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.0.4)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.9.16)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.9.0)\n",
            "Requirement already satisfied: submitit in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.5.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.19.3)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->-r requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (0.17.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit->-r requirements.txt (line 6)) (2.2.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.10/dist-packages (from submitit->-r requirements.txt (line 6)) (4.11.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (2024.5.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (4.66.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm->-r requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm->-r requirements.txt (line 4)) (1.3.0)\n",
            "/content/Mask2Former/mask2former/modeling/pixel_decoder/ops\n",
            "running build\n",
            "running build_py\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:500: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:415: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:425: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing MultiScaleDeformableAttention.egg-info/PKG-INFO\n",
            "writing dependency_links to MultiScaleDeformableAttention.egg-info/dependency_links.txt\n",
            "writing top-level names to MultiScaleDeformableAttention.egg-info/top_level.txt\n",
            "reading manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-cpython-310/MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/__init__.py -> build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/ms_deform_attn_func.py -> build/bdist.linux-x86_64/egg/functions\n",
            "creating build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/__init__.py -> build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/ms_deform_attn.py -> build/bdist.linux-x86_64/egg/modules\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/ms_deform_attn_func.py to ms_deform_attn_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/ms_deform_attn.py to ms_deform_attn.cpython-310.pyc\n",
            "creating stub loader for MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/MultiScaleDeformableAttention.py to MultiScaleDeformableAttention.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.MultiScaleDeformableAttention.cpython-310: module references __file__\n",
            "creating 'dist/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "removing '/usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Extracting MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "MultiScaleDeformableAttention 1.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for MultiScaleDeformableAttention==1.0\n",
            "Finished processing dependencies for MultiScaleDeformableAttention==1.0\n",
            "/content/Mask2Former\n"
          ]
        }
      ],
      "source": [
        "# clone and install Mask2Former\n",
        "!git clone https://github.com/facebookresearch/Mask2Former.git\n",
        "%cd Mask2Former\n",
        "!pip install -U opencv-python\n",
        "!pip install git+https://github.com/cocodataset/panopticapi.git\n",
        "!pip install -r requirements.txt\n",
        "%cd mask2former/modeling/pixel_decoder/ops\n",
        "!python setup.py build install\n",
        "%cd ../../../../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xGxctvB_Pdkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0292333-800e-4a10-c793-95ca646dfcf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-q9fifwdc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-q9fifwdc\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 0ae803b1449cd2d3f8fa1b7c0f59356db10b3083\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.4.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.15.2)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.2.1)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.11.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccGvME_lQkbN",
        "outputId": "f7d6085b-5f6b-4e41-df89-7115a9cf3a7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Mask2Former/mask2former/modeling/pixel_decoder/ops\n"
          ]
        }
      ],
      "source": [
        "%cd mask2former/modeling/pixel_decoder/ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xP44DZ_zQooA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c1df84-9c0c-4cba-ae66-155406b21043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running build\n",
            "running build_py\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:500: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:415: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:425: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing MultiScaleDeformableAttention.egg-info/PKG-INFO\n",
            "writing dependency_links to MultiScaleDeformableAttention.egg-info/dependency_links.txt\n",
            "writing top-level names to MultiScaleDeformableAttention.egg-info/top_level.txt\n",
            "reading manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-cpython-310/MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/__init__.py -> build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/ms_deform_attn_func.py -> build/bdist.linux-x86_64/egg/functions\n",
            "creating build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/__init__.py -> build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/ms_deform_attn.py -> build/bdist.linux-x86_64/egg/modules\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/ms_deform_attn_func.py to ms_deform_attn_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/ms_deform_attn.py to ms_deform_attn.cpython-310.pyc\n",
            "creating stub loader for MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/MultiScaleDeformableAttention.py to MultiScaleDeformableAttention.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.MultiScaleDeformableAttention.cpython-310: module references __file__\n",
            "creating 'dist/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "removing '/usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Extracting MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "MultiScaleDeformableAttention 1.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for MultiScaleDeformableAttention==1.0\n",
            "Finished processing dependencies for MultiScaleDeformableAttention==1.0\n"
          ]
        }
      ],
      "source": [
        "!sh make.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fy0WqfqBQsqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfeb2c24-50a9-4772-82fe-07cfa99d7eb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Mask2Former\n"
          ]
        }
      ],
      "source": [
        "%cd ../../../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "outputs": [],
      "source": [
        "# import Mask2Former project\n",
        "from mask2former import add_maskformer2_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NvJwaL06RNCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a26485e-b46d-42a3-b405-da9163faa4b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aQ-zjQCtRU1F"
      },
      "outputs": [],
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "setup_logger(name=\"mask2former\")\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.projects.deeplab import add_deeplab_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wg5JCtyWRZOo"
      },
      "outputs": [],
      "source": [
        "data_dir_path = \"/content/drive/MyDrive/instseg/data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7EO4nMI9Rb5P"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"taco_train\", {}, data_dir_path + \"annotations_0_train.json\", data_dir_path + \"images/\")\n",
        "register_coco_instances(\"taco_val\", {}, data_dir_path + \"annotations_0_val.json\", data_dir_path + \"images/\")\n",
        "register_coco_instances(\"taco_test\", {}, data_dir_path + \"annotations_0_test.json\", data_dir_path + \"images/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ND0BUQdjRexF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load your JSON file\n",
        "with open('/content/drive/MyDrive/instseg/data/annotations_0_train.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Generate unique IDs\n",
        "unique_id = 0\n",
        "for annotation in data['annotations']:\n",
        "    annotation['id'] = unique_id\n",
        "    unique_id += 1\n",
        "\n",
        "# Save the corrected JSON back to file\n",
        "with open('/content/drive/MyDrive/instseg/data/annotations_0_train.json', 'w') as f:\n",
        "    json.dump(data, f, indent=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y44xCY4Gu_ou"
      },
      "source": [
        "# Fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IZL4O9aw3XXp"
      },
      "outputs": [],
      "source": [
        "from detectron2.data import DatasetMapper, build_detection_train_loader\n",
        "from detectron2.data import detection_utils as utils\n",
        "from detectron2.structures import PolygonMasks\n",
        "import copy\n",
        "import torch  # Import torch to convert images to tensors\n",
        "from argparse import ArgumentParser\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import build_detection_train_loader\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.projects.deeplab import add_deeplab_config\n",
        "import detectron2.utils.comm as comm\n",
        "from detectron2.utils.logger import setup_logger\n",
        "from mask2former import (\n",
        "    MaskFormerInstanceDatasetMapper,\n",
        "    InstanceSegEvaluator,\n",
        "    add_maskformer2_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6kaK-F3shWqR"
      },
      "outputs": [],
      "source": [
        "class Trainer(DefaultTrainer):\n",
        "    \"\"\"\n",
        "    Extension of the Trainer class adapted to MaskFormer.\n",
        "    \"\"\"\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        if cfg.INPUT.DATASET_MAPPER_NAME == \"mask_former_instance\":\n",
        "            mapper = MaskFormerInstanceDatasetMapper(cfg, True)\n",
        "            return build_detection_train_loader(cfg, mapper=mapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6FlsDz1hq_54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "\n",
        "cfg = get_cfg()\n",
        "add_deeplab_config(cfg)\n",
        "add_maskformer2_config(cfg)\n",
        "\n",
        "cfg.merge_from_file(\"configs/coco/instance-segmentation/maskformer2_R50_bs16_50ep.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqnpT1xzusDm",
        "outputId": "04bb039a-5189-4fa7-afc2-4dc2748ec978"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_SQRT: True\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  COLOR_AUG_SSD: False\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SINGLE_CATEGORY_MAX_AREA: 1.0\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  DATASET_MAPPER_NAME: coco_instance_lsj\n",
            "  FORMAT: RGB\n",
            "  IMAGE_SIZE: 1024\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SCALE: 2.0\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SCALE: 0.1\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (800,)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "  SIZE_DIVISIBILITY: -1\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32, 64, 128, 256, 512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 0\n",
            "    NAME: build_resnet_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: []\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_FORMER:\n",
            "    CLASS_WEIGHT: 2.0\n",
            "    DEC_LAYERS: 10\n",
            "    DEEP_SUPERVISION: True\n",
            "    DICE_WEIGHT: 5.0\n",
            "    DIM_FEEDFORWARD: 2048\n",
            "    DROPOUT: 0.0\n",
            "    ENC_LAYERS: 0\n",
            "    ENFORCE_INPUT_PROJ: False\n",
            "    HIDDEN_DIM: 256\n",
            "    IMPORTANCE_SAMPLE_RATIO: 0.75\n",
            "    MASK_WEIGHT: 5.0\n",
            "    NHEADS: 8\n",
            "    NO_OBJECT_WEIGHT: 0.1\n",
            "    NUM_OBJECT_QUERIES: 100\n",
            "    OVERSAMPLE_RATIO: 3.0\n",
            "    PRE_NORM: False\n",
            "    SIZE_DIVISIBILITY: 32\n",
            "    TEST:\n",
            "      INSTANCE_ON: True\n",
            "      OBJECT_MASK_THRESHOLD: 0.8\n",
            "      OVERLAP_THRESHOLD: 0.8\n",
            "      PANOPTIC_ON: False\n",
            "      SEMANTIC_ON: False\n",
            "      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: False\n",
            "    TRAIN_NUM_POINTS: 12544\n",
            "    TRANSFORMER_DECODER_NAME: MultiScaleMaskedTransformerDecoder\n",
            "    TRANSFORMER_IN_FEATURE: multi_scale_pixel_decoder\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: MaskFormer\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [123.675, 116.28, 103.53]\n",
            "  PIXEL_STD: [58.395, 57.12, 57.375]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 50\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES4_DILATION: 1\n",
            "    RES5_DILATION: 1\n",
            "    RES5_MULTI_GRID: [1, 1, 1]\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STEM_TYPE: basic\n",
            "    STRIDE_IN_1X1: False\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    FED_LOSS_FREQ_WEIGHT_POWER: 0.5\n",
            "    FED_LOSS_NUM_CLASSES: 50\n",
            "    NAME: \n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 0\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "    USE_FED_LOSS: False\n",
            "    USE_SIGMOID_CE: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['res4']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: Res5ROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 80\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['res4']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 2000\n",
            "    PRE_NMS_TOPK_TEST: 6000\n",
            "    PRE_NMS_TOPK_TRAIN: 12000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    ASPP_CHANNELS: 256\n",
            "    ASPP_DILATIONS: [6, 12, 18]\n",
            "    ASPP_DROPOUT: 0.1\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 256\n",
            "    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ['res3', 'res4', 'res5']\n",
            "    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8\n",
            "    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    LOSS_TYPE: hard_pixel_mining\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MASK_DIM: 256\n",
            "    NAME: MaskFormerHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 80\n",
            "    PIXEL_DECODER_NAME: MSDeformAttnPixelDecoder\n",
            "    PROJECT_CHANNELS: [48]\n",
            "    PROJECT_FEATURES: ['res2']\n",
            "    TRANSFORMER_ENC_LAYERS: 6\n",
            "    USE_DEPTHWISE_SEPARABLE_CONV: False\n",
            "  SWIN:\n",
            "    APE: False\n",
            "    ATTN_DROP_RATE: 0.0\n",
            "    DEPTHS: [2, 2, 6, 2]\n",
            "    DROP_PATH_RATE: 0.3\n",
            "    DROP_RATE: 0.0\n",
            "    EMBED_DIM: 96\n",
            "    MLP_RATIO: 4.0\n",
            "    NUM_HEADS: [3, 6, 12, 24]\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    PATCH_NORM: True\n",
            "    PATCH_SIZE: 4\n",
            "    PRETRAIN_IMG_SIZE: 224\n",
            "    QKV_BIAS: True\n",
            "    QK_SCALE: None\n",
            "    USE_CHECKPOINT: False\n",
            "    WINDOW_SIZE: 7\n",
            "  WEIGHTS: detectron2://ImageNetPretrained/torchvision/R-50.pkl\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: True\n",
            "  BACKBONE_MULTIPLIER: 0.1\n",
            "  BASE_LR: 0.0001\n",
            "  BASE_LR_END: 0.0\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: full_model\n",
            "    CLIP_VALUE: 0.01\n",
            "    ENABLED: True\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 368750\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  NUM_DECAYS: 3\n",
            "  OPTIMIZER: ADAMW\n",
            "  POLY_LR_CONSTANT_ENDING: 0.0\n",
            "  POLY_LR_POWER: 0.9\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  RESCALE_INTERVAL: False\n",
            "  STEPS: (327778, 355092)\n",
            "  WARMUP_FACTOR: 1.0\n",
            "  WARMUP_ITERS: 10\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.05\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_EMBED: 0.0\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 5000\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.DATASETS.TRAIN = (\"taco_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "\n",
        "cfg.INPUT.DATASET_MAPPER_NAME = \"mask_former_instance\"\n",
        "\n",
        "cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES = 60\n",
        "cfg.MODEL.WEIGHTS = \"https://dl.fbaipublicfiles.com/maskformer/mask2former/coco/instance/maskformer2_R50_bs16_50ep/model_final_3c8ec9.pkl\"\n",
        "cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE = \"value\"\n",
        "cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 300\n",
        "cfg.SOLVER.STEPS = []\n",
        "\n",
        "cfg.OUTPUT_DIR = \"./output\"\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "trainer = Trainer(cfg)\n",
        "trainer.resume_or_load(resume=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4FdGn2TvPAn",
        "outputId": "ef6574d5-38e1-40f6-f2a8-3d14fc6f5cda"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/10 13:44:05 d2.engine.defaults]: Model:\n",
            "MaskFormer(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (sem_seg_head): MaskFormerHead(\n",
            "    (pixel_decoder): MSDeformAttnPixelDecoder(\n",
            "      (input_proj): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "        )\n",
            "      )\n",
            "      (transformer): MSDeformAttnTransformerEncoderOnly(\n",
            "        (encoder): MSDeformAttnTransformerEncoder(\n",
            "          (layers): ModuleList(\n",
            "            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(\n",
            "              (self_attn): MSDeformAttn(\n",
            "                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)\n",
            "                (attention_weights): Linear(in_features=256, out_features=96, bias=True)\n",
            "                (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "                (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "              )\n",
            "              (dropout1): Dropout(p=0.0, inplace=False)\n",
            "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (dropout2): Dropout(p=0.0, inplace=False)\n",
            "              (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              (dropout3): Dropout(p=0.0, inplace=False)\n",
            "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
            "          num_pos_feats: 128\n",
            "          temperature: 10000\n",
            "          normalize: True\n",
            "          scale: 6.283185307179586\n",
            "      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (adapter_1): Conv2d(\n",
            "        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "      )\n",
            "      (layer_1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "      )\n",
            "    )\n",
            "    (predictor): MultiScaleMaskedTransformerDecoder(\n",
            "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
            "          num_pos_feats: 128\n",
            "          temperature: 10000\n",
            "          normalize: True\n",
            "          scale: 6.283185307179586\n",
            "      (transformer_self_attention_layers): ModuleList(\n",
            "        (0-8): 9 x SelfAttentionLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (transformer_cross_attention_layers): ModuleList(\n",
            "        (0-8): 9 x CrossAttentionLayer(\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (transformer_ffn_layers): ModuleList(\n",
            "        (0-8): 9 x FFNLayer(\n",
            "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (query_feat): Embedding(100, 256)\n",
            "      (query_embed): Embedding(100, 256)\n",
            "      (level_embed): Embedding(3, 256)\n",
            "      (input_proj): ModuleList(\n",
            "        (0-2): 3 x Sequential()\n",
            "      )\n",
            "      (class_embed): Linear(in_features=256, out_features=61, bias=True)\n",
            "      (mask_embed): MLP(\n",
            "        (layers): ModuleList(\n",
            "          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (criterion): Criterion SetCriterion\n",
            "      matcher: Matcher HungarianMatcher\n",
            "          cost_class: 2.0\n",
            "          cost_mask: 5.0\n",
            "          cost_dice: 5.0\n",
            "      losses: ['labels', 'masks']\n",
            "      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}\n",
            "      num_classes: 60\n",
            "      eos_coef: 0.1\n",
            "      num_points: 12544\n",
            "      oversample_ratio: 3.0\n",
            "      importance_sample_ratio: 0.75\n",
            ")\n",
            "[05/10 13:44:05 mask2former.data.dataset_mappers.mask_former_instance_dataset_mapper]: [MaskFormerInstanceDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "WARNING [05/10 13:44:05 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[05/10 13:44:05 d2.data.datasets.coco]: Loaded 1200 images in COCO format from /content/drive/MyDrive/instseg/data/annotations_0_train.json\n",
            "[05/10 13:44:05 d2.data.build]: Removed 0 images with no usable annotations. 1200 images left.\n",
            "[05/10 13:44:05 d2.data.build]: Distribution of instances among all 60 categories:\n",
            "|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
            "| Aluminium f.. | 49           |    Battery    | 2            | Aluminium b.. | 5            |\n",
            "| Carded blis.. | 1            | Other plast.. | 42           | Clear plast.. | 226          |\n",
            "| Glass bottle  | 76           | Plastic bot.. | 168          | Metal bottl.. | 58           |\n",
            "| Broken glass  | 121          |   Food Can    | 26           |    Aerosol    | 8            |\n",
            "|   Drink can   | 160          |  Toilet tube  | 4            | Other carton  | 77           |\n",
            "|  Egg carton   | 11           | Drink carton  | 30           | Corrugated .. | 50           |\n",
            "|  Meal carton  | 26           |   Pizza box   | 1            |   Paper cup   | 51           |\n",
            "| Disposable .. | 81           |   Foam cup    | 10           |   Glass cup   | 6            |\n",
            "| Other plast.. | 2            |  Food waste   | 5            |   Glass jar   | 3            |\n",
            "|  Plastic lid  | 59           |   Metal lid   | 4            | Other plastic | 217          |\n",
            "| Magazine pa.. | 5            |    Tissues    | 33           | Wrapping pa.. | 10           |\n",
            "| Normal paper  | 66           |   Paper bag   | 27           | Plastified .. | 0            |\n",
            "| Plastic film  | 359          | Six pack ri.. | 4            |  Garbage bag  | 27           |\n",
            "| Other plast.. | 223          | Single-use .. | 47           | Polypropyle.. | 2            |\n",
            "| Crisp packet  | 35           |  Spread tub   | 6            |  Tupperware   | 4            |\n",
            "| Disposable .. | 29           | Foam food c.. | 10           | Other plast.. | 5            |\n",
            "| Plastic glo.. | 3            | Plastic ute.. | 30           |    Pop tab    | 75           |\n",
            "| Rope & stri.. | 20           |  Scrap metal  | 17           |     Shoe      | 4            |\n",
            "| Squeezable .. | 5            | Plastic straw | 104          |  Paper straw  | 4            |\n",
            "| Styrofoam p.. | 96           | Unlabeled l.. | 425          |   Cigarette   | 457          |\n",
            "|               |              |               |              |               |              |\n",
            "|     total     | 3711         |               |              |               |              |\n",
            "[05/10 13:44:05 d2.data.build]: Using training sampler TrainingSampler\n",
            "[05/10 13:44:05 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[05/10 13:44:05 d2.data.common]: Serializing 1200 elements to byte tensors and concatenating them all ...\n",
            "[05/10 13:44:05 d2.data.common]: Serialized dataset takes 1.77 MiB\n",
            "[05/10 13:44:05 d2.data.build]: Making batched data loader with batch_size=2\n",
            "[05/10 13:44:05 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/maskformer/mask2former/coco/instance/maskformer2_R50_bs16_50ep/model_final_3c8ec9.pkl ...\n",
            "WARNING [05/10 13:44:05 mask2former.modeling.transformer_decoder.mask2former_transformer_decoder]: Weight format of MultiScaleMaskedTransformerDecoder have changed! Please upgrade your models. Applying automatic conversion now ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (81, 256) in the checkpoint but (61, 256) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (61,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (81,) in the checkpoint but (61,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "criterion.empty_weight\n",
            "sem_seg_head.predictor.class_embed.{bias, weight}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAuliSkJQer3",
        "outputId": "d032262c-f76f-4f27-d62f-80c3f6167428"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/10 13:44:14 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[05/10 13:44:38 d2.utils.events]:  eta: 0:03:56  iter: 19  total_loss: 102.9  loss_ce: 5.905  loss_mask: 0.1864  loss_dice: 1.948  loss_ce_0: 8.838  loss_mask_0: 0.1969  loss_dice_0: 2.431  loss_ce_1: 5.884  loss_mask_1: 0.1983  loss_dice_1: 2.314  loss_ce_2: 6.056  loss_mask_2: 0.2443  loss_dice_2: 2.348  loss_ce_3: 6.089  loss_mask_3: 0.2218  loss_dice_3: 2.061  loss_ce_4: 5.583  loss_mask_4: 0.2304  loss_dice_4: 2.177  loss_ce_5: 5.474  loss_mask_5: 0.1978  loss_dice_5: 2.116  loss_ce_6: 5.985  loss_mask_6: 0.1926  loss_dice_6: 2.078  loss_ce_7: 5.884  loss_mask_7: 0.2012  loss_dice_7: 1.94  loss_ce_8: 5.741  loss_mask_8: 0.1957  loss_dice_8: 1.833    time: 0.9061  last_time: 0.5307  data_time: 0.3702  last_data_time: 0.0314   lr: 0.00025  max_mem: 7801M\n",
            "[05/10 13:44:56 d2.utils.events]:  eta: 0:03:31  iter: 39  total_loss: 70.67  loss_ce: 2.715  loss_mask: 0.4728  loss_dice: 3.257  loss_ce_0: 6.812  loss_mask_0: 0.3994  loss_dice_0: 3.171  loss_ce_1: 2.626  loss_mask_1: 0.5373  loss_dice_1: 3.365  loss_ce_2: 2.681  loss_mask_2: 0.3774  loss_dice_2: 3.167  loss_ce_3: 2.786  loss_mask_3: 0.3344  loss_dice_3: 3.133  loss_ce_4: 2.52  loss_mask_4: 0.603  loss_dice_4: 3.223  loss_ce_5: 2.54  loss_mask_5: 0.4893  loss_dice_5: 3.371  loss_ce_6: 2.622  loss_mask_6: 0.3847  loss_dice_6: 3.252  loss_ce_7: 2.58  loss_mask_7: 0.4243  loss_dice_7: 3.295  loss_ce_8: 2.644  loss_mask_8: 0.4193  loss_dice_8: 3.076    time: 0.8317  last_time: 0.5107  data_time: 0.2049  last_data_time: 0.0078   lr: 0.00025  max_mem: 7802M\n",
            "[05/10 13:45:12 d2.utils.events]:  eta: 0:03:10  iter: 59  total_loss: 60.12  loss_ce: 2.371  loss_mask: 0.4279  loss_dice: 2.346  loss_ce_0: 4.324  loss_mask_0: 0.2719  loss_dice_0: 2.462  loss_ce_1: 2.173  loss_mask_1: 0.3304  loss_dice_1: 2.731  loss_ce_2: 2.226  loss_mask_2: 0.3962  loss_dice_2: 2.549  loss_ce_3: 2.335  loss_mask_3: 0.4203  loss_dice_3: 2.533  loss_ce_4: 2.223  loss_mask_4: 0.4111  loss_dice_4: 2.447  loss_ce_5: 2.447  loss_mask_5: 0.3674  loss_dice_5: 2.711  loss_ce_6: 2.237  loss_mask_6: 0.3733  loss_dice_6: 2.777  loss_ce_7: 2.432  loss_mask_7: 0.3969  loss_dice_7: 2.824  loss_ce_8: 2.368  loss_mask_8: 0.41  loss_dice_8: 2.596    time: 0.8301  last_time: 0.7253  data_time: 0.2919  last_data_time: 0.2208   lr: 0.00025  max_mem: 7802M\n",
            "[05/10 13:45:28 d2.utils.events]:  eta: 0:02:52  iter: 79  total_loss: 67.68  loss_ce: 2.707  loss_mask: 0.2706  loss_dice: 3.277  loss_ce_0: 3.544  loss_mask_0: 0.2554  loss_dice_0: 3.167  loss_ce_1: 3.131  loss_mask_1: 0.2967  loss_dice_1: 3.271  loss_ce_2: 3.09  loss_mask_2: 0.2565  loss_dice_2: 3.463  loss_ce_3: 3.063  loss_mask_3: 0.2212  loss_dice_3: 3.216  loss_ce_4: 2.891  loss_mask_4: 0.2442  loss_dice_4: 3.201  loss_ce_5: 2.868  loss_mask_5: 0.2788  loss_dice_5: 3.14  loss_ce_6: 2.909  loss_mask_6: 0.2217  loss_dice_6: 3.05  loss_ce_7: 2.861  loss_mask_7: 0.2814  loss_dice_7: 3.293  loss_ce_8: 2.841  loss_mask_8: 0.2705  loss_dice_8: 3.235    time: 0.8270  last_time: 0.8794  data_time: 0.2636  last_data_time: 0.3723   lr: 0.00025  max_mem: 7805M\n",
            "[05/10 13:45:43 d2.utils.events]:  eta: 0:02:30  iter: 99  total_loss: 63.18  loss_ce: 2.375  loss_mask: 0.4451  loss_dice: 3.064  loss_ce_0: 2.865  loss_mask_0: 0.4316  loss_dice_0: 3.066  loss_ce_1: 2.5  loss_mask_1: 0.4185  loss_dice_1: 3.13  loss_ce_2: 2.497  loss_mask_2: 0.3693  loss_dice_2: 3.312  loss_ce_3: 2.416  loss_mask_3: 0.4669  loss_dice_3: 3.216  loss_ce_4: 2.386  loss_mask_4: 0.4595  loss_dice_4: 3.307  loss_ce_5: 2.163  loss_mask_5: 0.3723  loss_dice_5: 3.306  loss_ce_6: 2.356  loss_mask_6: 0.34  loss_dice_6: 3.119  loss_ce_7: 2.297  loss_mask_7: 0.3196  loss_dice_7: 2.99  loss_ce_8: 2.363  loss_mask_8: 0.415  loss_dice_8: 3.043    time: 0.8050  last_time: 0.5201  data_time: 0.1447  last_data_time: 0.0040   lr: 0.00025  max_mem: 7805M\n",
            "[05/10 13:45:58 d2.utils.events]:  eta: 0:02:15  iter: 119  total_loss: 58.25  loss_ce: 2.023  loss_mask: 0.3945  loss_dice: 2.537  loss_ce_0: 2.167  loss_mask_0: 0.5082  loss_dice_0: 2.233  loss_ce_1: 2.032  loss_mask_1: 0.4864  loss_dice_1: 2.798  loss_ce_2: 2.106  loss_mask_2: 0.2364  loss_dice_2: 2.985  loss_ce_3: 2.023  loss_mask_3: 0.5212  loss_dice_3: 3.126  loss_ce_4: 1.806  loss_mask_4: 0.5367  loss_dice_4: 2.969  loss_ce_5: 1.866  loss_mask_5: 0.4144  loss_dice_5: 2.974  loss_ce_6: 1.709  loss_mask_6: 0.5471  loss_dice_6: 2.516  loss_ce_7: 1.746  loss_mask_7: 0.5182  loss_dice_7: 2.71  loss_ce_8: 1.784  loss_mask_8: 0.5312  loss_dice_8: 2.691    time: 0.7937  last_time: 0.5459  data_time: 0.1853  last_data_time: 0.0279   lr: 0.00025  max_mem: 7805M\n",
            "[05/10 13:46:12 d2.utils.events]:  eta: 0:01:58  iter: 139  total_loss: 54.06  loss_ce: 2.058  loss_mask: 0.3525  loss_dice: 2.496  loss_ce_0: 2.107  loss_mask_0: 0.339  loss_dice_0: 2.31  loss_ce_1: 1.933  loss_mask_1: 0.5191  loss_dice_1: 2.467  loss_ce_2: 2.083  loss_mask_2: 0.3892  loss_dice_2: 2.712  loss_ce_3: 2.087  loss_mask_3: 0.3777  loss_dice_3: 2.71  loss_ce_4: 1.985  loss_mask_4: 0.4322  loss_dice_4: 2.721  loss_ce_5: 1.973  loss_mask_5: 0.4208  loss_dice_5: 2.713  loss_ce_6: 2.053  loss_mask_6: 0.3312  loss_dice_6: 2.567  loss_ce_7: 2.03  loss_mask_7: 0.2906  loss_dice_7: 2.58  loss_ce_8: 2.003  loss_mask_8: 0.3362  loss_dice_8: 2.687    time: 0.7798  last_time: 0.5177  data_time: 0.1502  last_data_time: 0.0052   lr: 0.00025  max_mem: 7805M\n",
            "[05/10 13:46:27 d2.utils.events]:  eta: 0:01:41  iter: 159  total_loss: 54.55  loss_ce: 2.057  loss_mask: 0.3781  loss_dice: 2.088  loss_ce_0: 2.359  loss_mask_0: 0.3941  loss_dice_0: 2.181  loss_ce_1: 2.198  loss_mask_1: 0.557  loss_dice_1: 2.282  loss_ce_2: 2.312  loss_mask_2: 0.6598  loss_dice_2: 2.955  loss_ce_3: 2.492  loss_mask_3: 0.5426  loss_dice_3: 3.096  loss_ce_4: 2.116  loss_mask_4: 0.5549  loss_dice_4: 3.011  loss_ce_5: 2.041  loss_mask_5: 0.5607  loss_dice_5: 2.839  loss_ce_6: 1.956  loss_mask_6: 0.3564  loss_dice_6: 2.389  loss_ce_7: 2.048  loss_mask_7: 0.3152  loss_dice_7: 2.32  loss_ce_8: 2.06  loss_mask_8: 0.4005  loss_dice_8: 2.472    time: 0.7752  last_time: 0.5197  data_time: 0.2052  last_data_time: 0.0048   lr: 0.00025  max_mem: 7805M\n",
            "[05/10 13:46:40 d2.utils.events]:  eta: 0:01:25  iter: 179  total_loss: 60.37  loss_ce: 2.708  loss_mask: 0.4545  loss_dice: 2.557  loss_ce_0: 2.737  loss_mask_0: 0.5483  loss_dice_0: 2.389  loss_ce_1: 2.681  loss_mask_1: 0.4812  loss_dice_1: 2.535  loss_ce_2: 2.79  loss_mask_2: 0.5669  loss_dice_2: 2.282  loss_ce_3: 2.776  loss_mask_3: 0.4216  loss_dice_3: 2.5  loss_ce_4: 2.624  loss_mask_4: 0.4223  loss_dice_4: 2.541  loss_ce_5: 2.781  loss_mask_5: 0.4323  loss_dice_5: 2.783  loss_ce_6: 2.803  loss_mask_6: 0.3835  loss_dice_6: 2.669  loss_ce_7: 2.821  loss_mask_7: 0.3858  loss_dice_7: 2.549  loss_ce_8: 2.798  loss_mask_8: 0.4821  loss_dice_8: 2.582    time: 0.7658  last_time: 1.1539  data_time: 0.1631  last_data_time: 0.6401   lr: 0.00025  max_mem: 7805M\n",
            "[05/10 13:46:56 d2.utils.events]:  eta: 0:01:11  iter: 199  total_loss: 56.41  loss_ce: 2.413  loss_mask: 0.2902  loss_dice: 2.694  loss_ce_0: 2.259  loss_mask_0: 0.343  loss_dice_0: 2.401  loss_ce_1: 2.374  loss_mask_1: 0.3379  loss_dice_1: 2.714  loss_ce_2: 2.187  loss_mask_2: 0.3357  loss_dice_2: 2.677  loss_ce_3: 2.251  loss_mask_3: 0.3953  loss_dice_3: 2.476  loss_ce_4: 2.216  loss_mask_4: 0.409  loss_dice_4: 2.371  loss_ce_5: 2.236  loss_mask_5: 0.3303  loss_dice_5: 2.746  loss_ce_6: 2.186  loss_mask_6: 0.3523  loss_dice_6: 2.793  loss_ce_7: 2.228  loss_mask_7: 0.3494  loss_dice_7: 2.792  loss_ce_8: 2.328  loss_mask_8: 0.3815  loss_dice_8: 2.689    time: 0.7651  last_time: 0.8302  data_time: 0.2065  last_data_time: 0.3122   lr: 0.00025  max_mem: 7805M\n",
            "[05/10 13:47:12 d2.utils.events]:  eta: 0:00:57  iter: 219  total_loss: 58.59  loss_ce: 2.256  loss_mask: 0.3661  loss_dice: 2.743  loss_ce_0: 2.308  loss_mask_0: 0.4439  loss_dice_0: 2.708  loss_ce_1: 2.214  loss_mask_1: 0.3498  loss_dice_1: 2.432  loss_ce_2: 2.299  loss_mask_2: 0.4545  loss_dice_2: 2.929  loss_ce_3: 2.386  loss_mask_3: 0.397  loss_dice_3: 2.732  loss_ce_4: 2.223  loss_mask_4: 0.4094  loss_dice_4: 2.696  loss_ce_5: 2.249  loss_mask_5: 0.3196  loss_dice_5: 2.71  loss_ce_6: 2.268  loss_mask_6: 0.356  loss_dice_6: 2.661  loss_ce_7: 2.217  loss_mask_7: 0.3923  loss_dice_7: 2.67  loss_ce_8: 2.296  loss_mask_8: 0.3759  loss_dice_8: 2.735    time: 0.7705  last_time: 2.1261  data_time: 0.2832  last_data_time: 1.5040   lr: 0.00025  max_mem: 7805M\n",
            "[05/10 13:47:26 d2.utils.events]:  eta: 0:00:41  iter: 239  total_loss: 62.19  loss_ce: 2.335  loss_mask: 0.3198  loss_dice: 3.205  loss_ce_0: 2.191  loss_mask_0: 0.2333  loss_dice_0: 3.054  loss_ce_1: 2.227  loss_mask_1: 0.3008  loss_dice_1: 2.996  loss_ce_2: 2.459  loss_mask_2: 0.3528  loss_dice_2: 3.285  loss_ce_3: 2.277  loss_mask_3: 0.3087  loss_dice_3: 3.358  loss_ce_4: 2.353  loss_mask_4: 0.2833  loss_dice_4: 3.329  loss_ce_5: 2.311  loss_mask_5: 0.3143  loss_dice_5: 3.316  loss_ce_6: 2.285  loss_mask_6: 0.3052  loss_dice_6: 3.194  loss_ce_7: 2.284  loss_mask_7: 0.3215  loss_dice_7: 3.076  loss_ce_8: 2.309  loss_mask_8: 0.3221  loss_dice_8: 3.232    time: 0.7656  last_time: 0.5267  data_time: 0.1592  last_data_time: 0.0064   lr: 0.00025  max_mem: 7806M\n",
            "[05/10 13:47:40 d2.utils.events]:  eta: 0:00:27  iter: 259  total_loss: 56.64  loss_ce: 2.562  loss_mask: 0.3383  loss_dice: 2.689  loss_ce_0: 2.536  loss_mask_0: 0.3984  loss_dice_0: 2.469  loss_ce_1: 2.502  loss_mask_1: 0.4124  loss_dice_1: 2.363  loss_ce_2: 2.755  loss_mask_2: 0.4734  loss_dice_2: 2.852  loss_ce_3: 2.623  loss_mask_3: 0.362  loss_dice_3: 2.513  loss_ce_4: 2.722  loss_mask_4: 0.4063  loss_dice_4: 2.581  loss_ce_5: 2.555  loss_mask_5: 0.3826  loss_dice_5: 2.855  loss_ce_6: 2.459  loss_mask_6: 0.3678  loss_dice_6: 2.642  loss_ce_7: 2.551  loss_mask_7: 0.3909  loss_dice_7: 2.655  loss_ce_8: 2.428  loss_mask_8: 0.3457  loss_dice_8: 2.62    time: 0.7607  last_time: 0.5172  data_time: 0.1520  last_data_time: 0.0045   lr: 0.00025  max_mem: 7806M\n",
            "[05/10 13:47:56 d2.utils.events]:  eta: 0:00:13  iter: 279  total_loss: 46.5  loss_ce: 1.861  loss_mask: 0.2721  loss_dice: 2.323  loss_ce_0: 1.882  loss_mask_0: 0.1985  loss_dice_0: 2.214  loss_ce_1: 2.022  loss_mask_1: 0.2678  loss_dice_1: 2.444  loss_ce_2: 1.886  loss_mask_2: 0.265  loss_dice_2: 2.294  loss_ce_3: 1.893  loss_mask_3: 0.2191  loss_dice_3: 2.335  loss_ce_4: 1.824  loss_mask_4: 0.3051  loss_dice_4: 2.524  loss_ce_5: 1.653  loss_mask_5: 0.2436  loss_dice_5: 2.425  loss_ce_6: 1.836  loss_mask_6: 0.2375  loss_dice_6: 2.161  loss_ce_7: 1.895  loss_mask_7: 0.2222  loss_dice_7: 2.021  loss_ce_8: 1.87  loss_mask_8: 0.2239  loss_dice_8: 2.115    time: 0.7606  last_time: 0.6544  data_time: 0.2227  last_data_time: 0.0444   lr: 0.00025  max_mem: 7806M\n",
            "[05/10 13:48:13 d2.utils.events]:  eta: 0:00:00  iter: 299  total_loss: 52.98  loss_ce: 2.358  loss_mask: 0.1908  loss_dice: 2.42  loss_ce_0: 2.298  loss_mask_0: 0.2102  loss_dice_0: 2.237  loss_ce_1: 2.427  loss_mask_1: 0.2594  loss_dice_1: 2.76  loss_ce_2: 2.459  loss_mask_2: 0.3308  loss_dice_2: 2.604  loss_ce_3: 2.534  loss_mask_3: 0.2428  loss_dice_3: 2.689  loss_ce_4: 2.383  loss_mask_4: 0.2686  loss_dice_4: 2.679  loss_ce_5: 2.6  loss_mask_5: 0.3044  loss_dice_5: 2.492  loss_ce_6: 2.209  loss_mask_6: 0.3194  loss_dice_6: 2.56  loss_ce_7: 2.259  loss_mask_7: 0.3493  loss_dice_7: 2.625  loss_ce_8: 2.302  loss_mask_8: 0.3256  loss_dice_8: 2.644    time: 0.7640  last_time: 1.1560  data_time: 0.2653  last_data_time: 0.5323   lr: 0.00025  max_mem: 7806M\n",
            "[05/10 13:48:13 d2.engine.hooks]: Overall training speed: 298 iterations in 0:03:47 (0.7640 s / it)\n",
            "[05/10 13:48:13 d2.engine.hooks]: Total training time: 0:03:51 (0:00:03 on hooks)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}